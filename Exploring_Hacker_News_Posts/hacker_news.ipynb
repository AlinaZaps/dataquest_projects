{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to publish!\n",
    "\n",
    "\n",
    "Today we will analyze the data of the Hacker News website, and we will determine which categories are the most commented on and try to find out what is the best time for publications.\n",
    "\n",
    "You can find the data set [https://www.kaggle.com/hacker-news/hacker-news-posts](here), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "| name| description|\n",
    "| --- | --- |\n",
    "|id: | The unique identifier from Hacker News for the post|\n",
    "|title: | The title of the post|\n",
    "|url: | The URL that the posts links to, if the post has a URL|\n",
    "|num_points: | The number of points the post acquired|\n",
    "|num_comments: | The number of comments that were made on the post|\n",
    "|author: | The username of the person who submitted the post|\n",
    "|created_at: | The date and time at which the post was submitted|\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists. Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader \n",
    "hn = list(reader(open('hacker_news.csv')))\n",
    "header = hn.pop(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Since we're only\n",
    "concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separated the \"ask posts\" and the \"show posts\" into two list of lists named ask_posts and show_posts. Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(avg_ask_comments)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask posts receive more comments on average, because they are created in order to get the opinion of users. So we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    hour = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\").strftime(\"%H\")\n",
    "    comments_by_hour[hour] = comments_by_hour.get(hour, 0) + 1\n",
    "    counts_by_hour[hour] = counts_by_hour.get(hour, 0) + row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created two dictionaries:\n",
    "\n",
    "1. <font color='blue'>counts_by_hour</font>: contains the number of ask posts created during each hour of the day.\n",
    "2. <font color='blue'>comments_by_hour</font>: contains the corresponding number of comments ask posts created at each hour received.\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.595 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.525 average comments per post\n",
      "16:00: 16.796 average comments per post\n",
      "21:00: 16.009 average comments per post\n",
      "13:00: 14.741 average comments per post\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for el in counts_by_hour:\n",
    "    avg = counts_by_hour[el] / comments_by_hour[el]\n",
    "    avg_by_hour.append([el, '%.3f' % avg])\n",
    "\n",
    "avg_by_hour.sort()\n",
    "\n",
    "swap_avg_by_hour =  []\n",
    "for el in avg_by_hour:\n",
    "    swap_avg_by_hour.append([float(el[1]), el[0]])\n",
    "swap_avg_by_hour.sort(reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for el in swap_avg_by_hour[:6]:\n",
    "    template = '{hour}:00: {com_per_post} average comments per post'\n",
    "    print(template.format(hour = el[1],com_per_post = el[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
