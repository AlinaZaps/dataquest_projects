{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "In this project, we're going to study the practical side of the Naive Bayes algorithm by building a spam filter for SMS messages.\n",
    "\n",
    "Our goal is to create a spam filter that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "We'll use dataset, which was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\">The UCI Machine Learning Repository</a>. You can also download the dataset directly <a href=\"https://dq-content.s3.amazonaws.com/433/SMSSpamCollection\">from this link</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "sms_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating it, it's very helpful to first think of a way of testing how well it works. Once our spam filter is done, we'll need to test how good it is with classifying new messages. To test the spam filter, we're first going to split our dataset into two categories:\n",
    "\n",
    "- A training set, which we'll use to \"train\" the computer how to classify messages.\n",
    "- A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep 80% of our dataset for training, and 20% for testing. The dataset has 5,572 messages, which means that:\n",
    "\n",
    "- The training set will have 4,458 messages.\n",
    "- The test set will have 1,114 messages.\n",
    "\n",
    "\n",
    "Let's start by randomizing the entire dataset to ensure that spam and ham messages are spread properly throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sms_training: \n",
      " ham     86.496187\n",
      "spam    13.503813\n",
      "Name: Label, dtype: float64 \n",
      "\n",
      "Sms_test: \n",
      " ham     86.983842\n",
      "spam    13.016158\n",
      "Name: Label, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms_spam.sample(frac=1, random_state=1)\n",
    "sms_training = sms_spam.iloc[:4458].reset_index(drop=True)\n",
    "sms_test = sms_spam.iloc[4458:].reset_index(drop=True)\n",
    "\n",
    "# Find the percentage of spam and ham in both the training and the test set\n",
    "print('Sms_training: \\n', sms_training['Label'].value_counts(normalize=True)*100, '\\n')\n",
    "print('Sms_test: \\n', sms_test['Label'].value_counts(normalize=True)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "\n",
    "Next step is to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. Right now, our training and test sets have this format:\n",
    "\n",
    "<img src=\"https://dq-content.s3.amazonaws.com/433/cpgp_dataset_1.png\" alt=\" \">\n",
    "\n",
    "To make the calculations easier, we want bring the data to this format:\n",
    "\n",
    "<img src=\"https://dq-content.s3.amazonaws.com/433/cpgp_dataset_2.png\" alt=\" \">\n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set before\n",
    "sms_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  go until jurong point  crazy   available only ...\n",
       "1   ham                      ok lar    joking wif u oni   \n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham  u dun say so early hor    u c already then say   \n",
       "4   ham  nah i don t think he goes to usf  he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Del punctuation and transform every letter to lower case\n",
    "\n",
    "sms_training['SMS'] = sms_training['SMS'].str.replace(r'\\W', ' ').str.lower()\n",
    "sms_training.head() # training set after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have to make vocabulary and create a list with all of the unique words that occur in the messages of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_list = []\n",
    "sms_training['SMS'] = sms_training['SMS'].str.split()\n",
    "\n",
    "for sms in sms_training['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary_list.append(word)\n",
    "        \n",
    "vocabulary_set = set(vocabulary_list)\n",
    "vocabulary = list(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7813"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are 7,813 unique words in all the messages of our training set.\n",
    "Now we build a dictionary that we'll then convert to the DataFrame we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(sms_training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for i, sms in enumerate(sms_training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...  0   0    0   \n",
       "1   ham                     [ok, lar, joking, wif, u, oni]  0   0    0   \n",
       "2  spam  [free, entry, in, 2, a, wkly, comp, to, win, f...  0   0    0   \n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...  0   0    0   \n",
       "4   ham  [nah, i, don, t, think, he, goes, to, usf, he,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585236  01223585334 ...  zhong  zindgi  \\\n",
       "0       0             0     0            0            0 ...      0       0   \n",
       "1       0             0     0            0            0 ...      0       0   \n",
       "2       0             0     0            0            0 ...      0       0   \n",
       "3       0             0     0            0            0 ...      0       0   \n",
       "4       0             0     0            0            0 ...      0       0   \n",
       "\n",
       "   zoe  zogtorius  zoom  zouk  zyada  èn  ú1  ü  \n",
       "0    0          0     0     0      0   0   0  0  \n",
       "1    0          0     0     0      0   0   0  0  \n",
       "2    0          0     0     0      0   0   0  0  \n",
       "3    0          0     0     0      0   0   0  0  \n",
       "4    0          0     0     0      0   0   0  0  \n",
       "\n",
       "[5 rows x 7815 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(data=word_counts_per_sms)\n",
    "\n",
    "sms_training_clean = pd.concat([sms_training, word_counts], axis=1)\n",
    "sms_training_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter.\n",
    "\n",
    "\n",
    "\n",
    "## Calculating Constants First\n",
    "\n",
    "The Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "Also, to calculate P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) inside the formulas above we need to use these equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "\n",
    "- P(Spam) and P(Ham)\n",
    "- N<sub>Spam</sub>, N <sub>Ham</sub>, N<sub>Vocabulary</sub>\n",
    "\n",
    "Remember that:\n",
    "- NSpam is equal to the number of words in all the spam messages.\n",
    "- NHam is equal to the number of words in all the non-spam messages.\n",
    "\n",
    "We'll also use Laplace smoothing and set <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>&#x03B1;<!-- α --></mi>\n",
    "  <mo>=</mo>\n",
    "  <mn>1</mn>\n",
    "</math>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# P(Spam) and P(Ham)\n",
    "p_spam = sms_training_clean['Label'].value_counts(normalize=1)['spam']\n",
    "p_ham = sms_training_clean['Label'].value_counts(normalize=1)['ham']\n",
    "\n",
    "# Isolating spam and ham messages\n",
    "spam_messages = sms_training_clean[sms_training_clean['Label'] == 'spam']\n",
    "ham_messages = sms_training_clean[sms_training_clean['Label'] == 'ham']\n",
    "\n",
    "# N_Spam, N_ham, N_vocabulary\n",
    "n_spam = spam_messages['SMS'].apply(len).sum()\n",
    "n_ham = ham_messages['SMS'].apply(len).sum()\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# initiate alpha\n",
    "alpha = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these terms will have constant values in our equations for every new message.\n",
    "\n",
    "How let's calculate the probability P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) for each word in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_spam_words = {unique_word: 0 for unique_word in vocabulary}\n",
    "p_ham_words = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_word_given_spam = (spam_messages[word].sum() + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    p_spam_words[word] = p_word_given_spam\n",
    "    \n",
    "    p_word_given_ham = (ham_messages[word].sum() + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    p_ham_words[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classifying A New Message\n",
    "\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter using these two equations:\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    message = message.replace(r'\\W', ' ').lower().split()\n",
    "    \n",
    "    p_spam_given_message = 1\n",
    "    p_ham_given_message = 1\n",
    "    for word in message:\n",
    "        if word in p_spam_words:\n",
    "            p_spam_given_message *= p_spam_words[word]\n",
    "        if word in p_ham_words:\n",
    "            p_ham_given_message *= p_ham_words[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "        \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 7.904810158987672e-18\n",
      "P(Ham|message): 2.6411793525822926e-19\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 9.630750386822645e-17\n",
      "P(Ham|message): 3.789612110065227e-14\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam filter accuracy testing\n",
    "\n",
    "The two results above look promising, but let's see how well the filter does on our test set, which has 1,114 messages.\n",
    "\n",
    "We'll start by writing a function that returns classification labels instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_sms_test(message):\n",
    "    message = message.replace(r'\\W', ' ').lower().split()\n",
    "    \n",
    "    p_spam_given_message = 1\n",
    "    p_ham_given_message = 1\n",
    "    for word in message:\n",
    "        if word in p_spam_words:\n",
    "            p_spam_given_message *= p_spam_words[word]\n",
    "        if word in p_ham_words:\n",
    "            p_ham_given_message *= p_ham_words[word]\n",
    "            \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight should I just plan to come up later toni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Die... I accidentally deleted e msg i suppose ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Welcome to UK-mobile-date this msg is FREE giv...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks again for your reply today. When is ur ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  Aight should I just plan to come up later toni...       ham\n",
       "1   ham  Die... I accidentally deleted e msg i suppose ...       ham\n",
       "2  spam  Welcome to UK-mobile-date this msg is FREE giv...      spam\n",
       "3   ham  This is wishing you a great day. Moji told me ...       ham\n",
       "4   ham  Thanks again for your reply today. When is ur ...       ham"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test['predicted'] = sms_test['SMS'].apply(classify_sms_test)\n",
    "sms_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write a function to measure the accuracy of our spam filter to find out how well our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1063\n",
      "Incorrect: 51\n",
      "Accuracy: 0.9542190305206463\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = sms_test.shape[0]\n",
    "\n",
    "for row in sms_test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] ==  row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 95.42%, which is quite good. Our spam filter looked at 1,114 messages and classified 1,063 correctly.\n",
    "\n",
    "## What's next?\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 95.42% on the test set we used, which is a pretty good result considering that our initial goal was an accuracy of over 80%.\n",
    "\n",
    "Next steps include:\n",
    "\n",
    "- Analyze the 51 messages that were classified incorrectly and try to figure out why the algorithm classified them incorrectly\n",
    "- Make the filtering process more complex by making the algorithm sensitive to letter case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
